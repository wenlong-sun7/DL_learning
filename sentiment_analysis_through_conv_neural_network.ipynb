{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46e0fe90b4934291b136e9c6f5b15b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f725b5462787493e988b613808d9bd64",
              "IPY_MODEL_c992defb41b44c44a343754ca6688a1d",
              "IPY_MODEL_7ab4a3181df3472485bcc034ae9a0ec0"
            ],
            "layout": "IPY_MODEL_d0911eacb0a248db969917861c9300e2"
          }
        },
        "f725b5462787493e988b613808d9bd64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8292abf1d7334cad869ec0fc7397495b",
            "placeholder": "​",
            "style": "IPY_MODEL_b0fee9cd2e5041d68d5f30d6dab8b97b",
            "value": "Map: 100%"
          }
        },
        "c992defb41b44c44a343754ca6688a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b68c6389b2de4c488e9dbf711074732e",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b792ed1b54b24c648a98bde841661539",
            "value": 25000
          }
        },
        "7ab4a3181df3472485bcc034ae9a0ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09f301d1d428447fa29cc24d5289abd9",
            "placeholder": "​",
            "style": "IPY_MODEL_eda1b500ae324789931bafbe54e923ec",
            "value": " 25000/25000 [00:05&lt;00:00, 4463.91 examples/s]"
          }
        },
        "d0911eacb0a248db969917861c9300e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8292abf1d7334cad869ec0fc7397495b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fee9cd2e5041d68d5f30d6dab8b97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b68c6389b2de4c488e9dbf711074732e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b792ed1b54b24c648a98bde841661539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09f301d1d428447fa29cc24d5289abd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda1b500ae324789931bafbe54e923ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2c3cc67c09244ac8345ac39c25fbca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dc58d5f041548f3bfbe0592b62cee76",
              "IPY_MODEL_f5c6b709cf054ff9976ab9b9b6731b70",
              "IPY_MODEL_93fc198fab9a44d194e9fe416ad10156"
            ],
            "layout": "IPY_MODEL_e8b2b66e2dbd4132a9d494846444d4cb"
          }
        },
        "7dc58d5f041548f3bfbe0592b62cee76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd785f5897264e48aa56386f574ea110",
            "placeholder": "​",
            "style": "IPY_MODEL_bc72840efedc40e891bd093633f9581b",
            "value": "Map: 100%"
          }
        },
        "f5c6b709cf054ff9976ab9b9b6731b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d486af1b714755843e7125ddf78b56",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf7ff0f23ddb48279acfc9c9c55f146b",
            "value": 25000
          }
        },
        "93fc198fab9a44d194e9fe416ad10156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b0bcd936334bf98cea03a01883f0ad",
            "placeholder": "​",
            "style": "IPY_MODEL_36aed374dd844cbca9f466cc85ee95aa",
            "value": " 25000/25000 [00:05&lt;00:00, 3154.51 examples/s]"
          }
        },
        "e8b2b66e2dbd4132a9d494846444d4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd785f5897264e48aa56386f574ea110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc72840efedc40e891bd093633f9581b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21d486af1b714755843e7125ddf78b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7ff0f23ddb48279acfc9c9c55f146b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27b0bcd936334bf98cea03a01883f0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36aed374dd844cbca9f466cc85ee95aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "376b9098390848fcb17d8bb86a8bb080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1937878fe1764415bf4f950858a8c7ec",
              "IPY_MODEL_5894d8fb4c5241d996343afa8b40a3e5",
              "IPY_MODEL_4cfcb6069a1a4f5a92795b8106de5c07"
            ],
            "layout": "IPY_MODEL_dcf69fe3d2774de685c7d4485a44c859"
          }
        },
        "1937878fe1764415bf4f950858a8c7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8cdb905f3f4884972655a7b4fe0893",
            "placeholder": "​",
            "style": "IPY_MODEL_a79fc0e8cc8144e9a7e7ff2e6ebdff02",
            "value": "Map: 100%"
          }
        },
        "5894d8fb4c5241d996343afa8b40a3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f78c0412ef43a6af2cfbef6dc76de6",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e65f1db381ee4d02ace16054b26edd89",
            "value": 20000
          }
        },
        "4cfcb6069a1a4f5a92795b8106de5c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57526fe5ef9d4152869c91b3bfeb3b43",
            "placeholder": "​",
            "style": "IPY_MODEL_076b204527224a03a543ec327f4ca987",
            "value": " 20000/20000 [00:08&lt;00:00, 2572.61 examples/s]"
          }
        },
        "dcf69fe3d2774de685c7d4485a44c859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8cdb905f3f4884972655a7b4fe0893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79fc0e8cc8144e9a7e7ff2e6ebdff02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7f78c0412ef43a6af2cfbef6dc76de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e65f1db381ee4d02ace16054b26edd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57526fe5ef9d4152869c91b3bfeb3b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076b204527224a03a543ec327f4ca987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "375ebcf8b9e343f08beaa6c8837f4f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f21bd1f42cbb4bf3b8ba94b687e8b0b4",
              "IPY_MODEL_19af8dcf515e4159b823fdeb51df3c79",
              "IPY_MODEL_66e5388dd23941a4a051a089cd95b3c4"
            ],
            "layout": "IPY_MODEL_597c94f268894705a9d9c2ea7550d074"
          }
        },
        "f21bd1f42cbb4bf3b8ba94b687e8b0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63d615d345794475bfd3d7138c06b57a",
            "placeholder": "​",
            "style": "IPY_MODEL_12c49e28e14245ccb2c093501b177ff6",
            "value": "Map: 100%"
          }
        },
        "19af8dcf515e4159b823fdeb51df3c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9c9bcc47da468695a8b7b84cdcc485",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5de695f1bb3048838431434346187cbf",
            "value": 5000
          }
        },
        "66e5388dd23941a4a051a089cd95b3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_695525703a084ce08994b003c722f7ce",
            "placeholder": "​",
            "style": "IPY_MODEL_bcfd2f41c5ba4608b6c348e930c1fd38",
            "value": " 5000/5000 [00:01&lt;00:00, 2808.64 examples/s]"
          }
        },
        "597c94f268894705a9d9c2ea7550d074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d615d345794475bfd3d7138c06b57a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c49e28e14245ccb2c093501b177ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f9c9bcc47da468695a8b7b84cdcc485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de695f1bb3048838431434346187cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "695525703a084ce08994b003c722f7ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcfd2f41c5ba4608b6c348e930c1fd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "940c866fc5ab4ef2983f6e278a130b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fddced62f3cd4014b156ff269519efe8",
              "IPY_MODEL_aff3d81eef3c4a28bc6e9adecb352be5",
              "IPY_MODEL_e8607534b5d54c369c23a228c04607c2"
            ],
            "layout": "IPY_MODEL_916f8b99a01845dcb701c79eac05e8d6"
          }
        },
        "fddced62f3cd4014b156ff269519efe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae0ced53f16243c785788ee1faab1eb6",
            "placeholder": "​",
            "style": "IPY_MODEL_3e8e783dc96545dab84e55b42627a4e9",
            "value": "Map: 100%"
          }
        },
        "aff3d81eef3c4a28bc6e9adecb352be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_450071c831e0476c99b3eb9d748378b7",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97494f0a9ac44c7ba809d6c59358a24f",
            "value": 25000
          }
        },
        "e8607534b5d54c369c23a228c04607c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b439ab65bf48dfa0511f0afb91f7fd",
            "placeholder": "​",
            "style": "IPY_MODEL_f805762d6b7e46f79de64a5c610c4b7f",
            "value": " 25000/25000 [00:08&lt;00:00, 2546.76 examples/s]"
          }
        },
        "916f8b99a01845dcb701c79eac05e8d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae0ced53f16243c785788ee1faab1eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8e783dc96545dab84e55b42627a4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "450071c831e0476c99b3eb9d748378b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97494f0a9ac44c7ba809d6c59358a24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24b439ab65bf48dfa0511f0afb91f7fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f805762d6b7e46f79de64a5c610c4b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5ofYe8vD8NW"
      },
      "outputs": [],
      "source": [
        "## This demo is a learning note from this github https://github.com/bentrevett/pytorch-sentiment-analysis/tree/main.\n",
        "\n",
        "### Learn how to retrain a word embedding using existing word embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchtext0.15.1 and Torch2.0.0 are compatible with each other for this demo!!"
      ],
      "metadata": {
        "id": "R0tj8cUREcAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.15.1 --no-cache-dir\n",
        "!pip install torch==2.0.0 --no-cache-dir\n",
        "!pip install datasets\n",
        "\n",
        "!pip show torchtext\n",
        "!pip show torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4d7NgH9Ef9H",
        "outputId": "5e36898f-a292-4499-9fe9-7dc3c2c7f34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.15.1\n",
            "  Downloading torchtext-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.32.3)\n",
            "Collecting torch==2.0.0 (from torchtext==0.15.1)\n",
            "  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (1.26.4)\n",
            "Collecting torchdata==0.6.0 (from torchtext==0.15.1)\n",
            "  Downloading torchdata-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (892 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n",
            "Downloading torchtext-0.15.1-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m212.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m303.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m149.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m302.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m194.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m334.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m211.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m199.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m158.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m180.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m193.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m225.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m249.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m179.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m287.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1 triton-2.0.0\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.4.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Name: torchtext\n",
            "Version: 0.15.1\n",
            "Summary: Text utilities and datasets for PyTorch\n",
            "Home-page: https://github.com/pytorch/text\n",
            "Author: PyTorch core devs and James Bradbury\n",
            "Author-email: jekbradbury@gmail.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: numpy, requests, torch, torchdata, tqdm\n",
            "Required-by: \n",
            "Name: torch\n",
            "Version: 2.0.0\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, jinja2, networkx, nvidia-cublas-cu11, nvidia-cuda-cupti-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11, nvidia-cufft-cu11, nvidia-curand-cu11, nvidia-cusolver-cu11, nvidia-cusparse-cu11, nvidia-nccl-cu11, nvidia-nvtx-cu11, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchdata, torchtext, torchvision, triton\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU info\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncj_kAczELw_",
        "outputId": "169289c0-0b8f-4119-8526-3da7a7b81463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 17 03:37:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0             42W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "# check whether gpu is available\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6CgrVEmEnBA",
        "outputId": "8eddae99-4c5a-4cf6-c586-7b1130512a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "StGTKMYgG6PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# load imdb dataset\n",
        "train, test = load_dataset(\"imdb\",split=['train','test'])"
      ],
      "metadata": {
        "id": "JFOSXIQvEoPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def example_tokneizer(example, tokenizer, max_length):\n",
        "  example['tokens'] = tokenizer(example['text'])[:max_length]\n",
        "  return example\n",
        "\n",
        "max_length = 256\n",
        "train = train.map(example_tokneizer,fn_kwargs={'tokenizer':tokenizer, 'max_length':max_length})\n",
        "test = test.map(example_tokneizer, fn_kwargs={'tokenizer':tokenizer, 'max_length':max_length})\n",
        "\n",
        "test_size=0.2\n",
        "tra = train.train_test_split(test_size=test_size,shuffle=True,seed=seed)\n",
        "train_dataset = tra['train']\n",
        "valid_dataset = tra['test']\n",
        "\n",
        "# build vocab\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "min_freq=5\n",
        "vocab = build_vocab_from_iterator(\n",
        "    train_dataset['tokens'],\n",
        "    min_freq=min_freq,\n",
        "    specials=[\"<unk>\",\"<pad>\"])\n",
        "\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "pad_sequence = vocab[\"<pad>\"]\n",
        "\n",
        "\n",
        "def numerize_tokens(example,vocab):\n",
        "  example['ids'] = vocab.lookup_indices(example['tokens'])\n",
        "  return example\n",
        "\n",
        "train_dataset = train_dataset.map(numerize_tokens,fn_kwargs={'vocab':vocab})\n",
        "valid_dataset = valid_dataset.map(numerize_tokens,fn_kwargs={'vocab':vocab})\n",
        "test_dataset = test.map(numerize_tokens,fn_kwargs={'vocab':vocab})\n",
        "\n",
        "# convert to tensor\n",
        "train_dataset = train_dataset.with_format(type='torch',columns=['ids','label'])\n",
        "valid_dataset = valid_dataset.with_format(type='torch',columns=['ids','label'])\n",
        "test_dataset = test_dataset.with_format(type='torch',columns=['ids','label'])\n",
        "\n",
        "\n",
        "# build collate function\n",
        "def collate_batch(pad_index):\n",
        "\n",
        "  def collate_fn(batch):\n",
        "    ids = [item['ids'] for item in batch]\n",
        "    labels = [item['label'] for item in batch]\n",
        "    ids = torch.nn.utils.rnn.pad_sequence(ids, padding_value=pad_index,batch_first=True, )\n",
        "    labels = torch.stack(labels)\n",
        "    return {'ids':ids, 'labels':labels}\n",
        "\n",
        "  return collate_fn\n",
        "\n",
        "def data_loader(dataset, batch_size, pad_sequence,shuffle=False):\n",
        "  collate_fn = collate_batch(pad_sequence)\n",
        "  loader = torch.utils.data.DataLoader(dataset = dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
        "  return loader\n",
        "\n",
        "# initialize dataloader\n",
        "batch_size = 512\n",
        "train_loader = data_loader(train_dataset, batch_size, pad_sequence,shuffle=True)\n",
        "valid_loader = data_loader(valid_dataset, batch_size, pad_sequence)\n",
        "test_loader = data_loader(test_dataset, batch_size,  pad_sequence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "46e0fe90b4934291b136e9c6f5b15b29",
            "f725b5462787493e988b613808d9bd64",
            "c992defb41b44c44a343754ca6688a1d",
            "7ab4a3181df3472485bcc034ae9a0ec0",
            "d0911eacb0a248db969917861c9300e2",
            "8292abf1d7334cad869ec0fc7397495b",
            "b0fee9cd2e5041d68d5f30d6dab8b97b",
            "b68c6389b2de4c488e9dbf711074732e",
            "b792ed1b54b24c648a98bde841661539",
            "09f301d1d428447fa29cc24d5289abd9",
            "eda1b500ae324789931bafbe54e923ec",
            "e2c3cc67c09244ac8345ac39c25fbca2",
            "7dc58d5f041548f3bfbe0592b62cee76",
            "f5c6b709cf054ff9976ab9b9b6731b70",
            "93fc198fab9a44d194e9fe416ad10156",
            "e8b2b66e2dbd4132a9d494846444d4cb",
            "dd785f5897264e48aa56386f574ea110",
            "bc72840efedc40e891bd093633f9581b",
            "21d486af1b714755843e7125ddf78b56",
            "bf7ff0f23ddb48279acfc9c9c55f146b",
            "27b0bcd936334bf98cea03a01883f0ad",
            "36aed374dd844cbca9f466cc85ee95aa",
            "376b9098390848fcb17d8bb86a8bb080",
            "1937878fe1764415bf4f950858a8c7ec",
            "5894d8fb4c5241d996343afa8b40a3e5",
            "4cfcb6069a1a4f5a92795b8106de5c07",
            "dcf69fe3d2774de685c7d4485a44c859",
            "eb8cdb905f3f4884972655a7b4fe0893",
            "a79fc0e8cc8144e9a7e7ff2e6ebdff02",
            "a7f78c0412ef43a6af2cfbef6dc76de6",
            "e65f1db381ee4d02ace16054b26edd89",
            "57526fe5ef9d4152869c91b3bfeb3b43",
            "076b204527224a03a543ec327f4ca987",
            "375ebcf8b9e343f08beaa6c8837f4f97",
            "f21bd1f42cbb4bf3b8ba94b687e8b0b4",
            "19af8dcf515e4159b823fdeb51df3c79",
            "66e5388dd23941a4a051a089cd95b3c4",
            "597c94f268894705a9d9c2ea7550d074",
            "63d615d345794475bfd3d7138c06b57a",
            "12c49e28e14245ccb2c093501b177ff6",
            "9f9c9bcc47da468695a8b7b84cdcc485",
            "5de695f1bb3048838431434346187cbf",
            "695525703a084ce08994b003c722f7ce",
            "bcfd2f41c5ba4608b6c348e930c1fd38",
            "940c866fc5ab4ef2983f6e278a130b2d",
            "fddced62f3cd4014b156ff269519efe8",
            "aff3d81eef3c4a28bc6e9adecb352be5",
            "e8607534b5d54c369c23a228c04607c2",
            "916f8b99a01845dcb701c79eac05e8d6",
            "ae0ced53f16243c785788ee1faab1eb6",
            "3e8e783dc96545dab84e55b42627a4e9",
            "450071c831e0476c99b3eb9d748378b7",
            "97494f0a9ac44c7ba809d6c59358a24f",
            "24b439ab65bf48dfa0511f0afb91f7fd",
            "f805762d6b7e46f79de64a5c610c4b7f"
          ]
        },
        "id": "Om-6cpmnFn09",
        "outputId": "1dd9924e-4535-4c6b-dff9-ad956457c552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46e0fe90b4934291b136e9c6f5b15b29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2c3cc67c09244ac8345ac39c25fbca2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "376b9098390848fcb17d8bb86a8bb080"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "375ebcf8b9e343f08beaa6c8837f4f97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "940c866fc5ab4ef2983f6e278a130b2d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym-YuhzMQdWp",
        "outputId": "8afcc37c-7afd-4d3d-db3d-f7f3c6a076ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['neg', 'pos'], id=None),\n",
              " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "train_loader = data_loader(train_dataset, batch_size, pad_sequence,shuffle=True)\n",
        "valid_loader = data_loader(valid_dataset, batch_size, pad_sequence)\n",
        "test_loader = data_loader(test_dataset, batch_size,  pad_sequence)\n",
        "\n",
        "print(f\"length of vocab: {len(vocab)}\")\n",
        "\n",
        "\n",
        "# build CNN\n",
        "class myCNN(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
        "    super().__init__()\n",
        "    self.embedding = torch.nn.Embedding(vocab_size, embedding_dim,padding_idx=pad_idx)\n",
        "    self.conv0 = torch.nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\n",
        "    self.fc = torch.nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "    self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, ids):\n",
        "    # [batch_size, seq_len] at beginning\n",
        "    embedded = self.dropout(self.embedding(ids))\n",
        "    print(f\"first embedded shape {embedded.shape}\")\n",
        "    # [batch_size,seq_len, embed_dimsion]\n",
        "    embedded = embedded.unsqueeze(1) # In PyTorch, unsqueeze(dim) adds a new dimension of size one at the specified dim. For unsqueeze(1), 256*300 becomes 1*256*300\n",
        "    print(f\"embedded shape {embedded.shape}\")\n",
        "    # [batch_size, 1, seq_len, dimension]\n",
        "    conved0 = torch.relu(self.conv0(embedded).squeeze(3)) # torch.relu(self.conv0(embedded) will return [batch-size, n_filters, seq-filter_size+1, 1]\n",
        "    print(f\"conved0 shape {conved0.shape}\") ## note there will also bias randomly initialized!!!!\n",
        "    # [batch_size, n_filters, seq_len - filter_size+1]\n",
        "    conved1 = torch.relu(self.conv1(embedded).squeeze(3))\n",
        "    print(f\"conved1 shape {conved1.shape}\")\n",
        "    pooled0 = torch.nn.functional.max_pool1d(conved0, conved0.shape[2]).squeeze(2)\n",
        "    print(f\"pooled0 shape {pooled0.shape}\")\n",
        "    # [batch_size,n_filters]\n",
        "    pooled1 = torch.nn.functional.max_pool1d(conved1, conved1.shape[2]).squeeze(2)\n",
        "    print(f\"pooled1 shape {pooled1.shape}\")\n",
        "    cat = self.dropout(torch.cat((pooled0, pooled1), dim=1))\n",
        "    print(f\"cat shape {cat.shape}\")\n",
        "    prediction = self.fc(cat)\n",
        "    print(f\"prediction shape {prediction.shape}\")\n",
        "    return prediction\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 300\n",
        "n_filters = 100\n",
        "filter_sizes = [8,16] # this actually means a filter with 8*embed_dimension, 16*embed_dimension\n",
        "# this is saying that we are looking at 8-gram, 16-gram, so these values usually  are 2,3,4\n",
        "# note we can also use something like [(8,8),(16,16)]\n",
        "output_dim = len(train_dataset.unique(\"label\"))\n",
        "dropout = 0.25\n",
        "pad_idx = vocab[\"<pad>\"]\n",
        "\n",
        "model = myCNN(vocab_size, embed_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx)\n",
        "\n",
        "vectors = torchtext.vocab.GloVe(name='6B',dim=300)\n",
        "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n",
        "model.embedding.weight.data = pretrained_embedding\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "def accuracy(prediction, label):\n",
        "    batch_size, _ = prediction.shape\n",
        "    predicted_classes = prediction.argmax(dim=-1)\n",
        "    correct_predictions = predicted_classes.eq(label).sum()\n",
        "    accuracy = correct_predictions / batch_size\n",
        "    return accuracy\n",
        "#\n",
        "\n",
        "optim = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "criterion.to(device)\n",
        "model.to(device)\n",
        "\n",
        "# define train function with batch\n",
        "def train(model, data_loader, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  for batch in tqdm.tqdm(data_loader, desc=\"training...\"):\n",
        "    ids = batch['ids'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(ids).squeeze(1)\n",
        "    loss = criterion(predictions, labels)\n",
        "    acc = accuracy(predictions, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(data_loader), epoch_acc / len(data_loader)\n",
        "\n",
        "def evaluate(model, data_loader, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "      ids = batch['ids'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "      predictions = model(ids).squeeze(1)\n",
        "      loss = criterion(predictions, labels)\n",
        "      acc = accuracy(predictions, labels)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(data_loader), epoch_acc / len(data_loader)\n",
        "\n",
        "\n",
        "epochs= 5\n",
        "# loop through epoch and record train and valid loss and accurcay\n",
        "from collections import defaultdict\n",
        "import tqdm\n",
        "\n",
        "train_loss = defaultdict(list)\n",
        "train_acc = defaultdict(list)\n",
        "valid_loss = defaultdict(list)\n",
        "valid_acc = defaultdict(list)\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in tqdm.tqdm(range(epochs)):\n",
        "  train_loss_epoch, train_acc_epoch = train(model, train_loader, optim, criterion)\n",
        "  valid_loss_epoch, valid_acc_epoch = evaluate(model, valid_loader, criterion)\n",
        "  train_loss[epoch].append(train_loss_epoch)\n",
        "  train_acc[epoch].append(train_acc_epoch)\n",
        "  valid_loss[epoch].append(valid_loss_epoch)\n",
        "  valid_acc[epoch].append(valid_acc_epoch)\n",
        "  if valid_loss_epoch < best_valid_loss:\n",
        "        best_valid_loss = valid_loss_epoch\n",
        "        torch.save(model.state_dict(), \"cnn.pt\")\n",
        "  print(f\"epoch: {epoch}\")\n",
        "  print(f\"train_loss: {train_loss_epoch:.3f}, train_acc: {train_acc_epoch:.3f}\")\n",
        "  print(f\"valid_loss: {valid_loss_epoch:.3f}, valid_acc: {valid_acc_epoch:.3f}\")\n",
        "\n",
        "# plot train and valid loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss.values(), label='train loss')\n",
        "plt.plot(valid_loss.values(), label='valid loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot train and valid accuracy\n",
        "plt.plot(train_acc.values(), label='train acc')\n",
        "plt.plot(valid_acc.values(), label='valid acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AayW5oUlQxag",
        "outputId": "ec9e57fb-2db2-44a5-fa1e-0c7edf8afb52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of vocab: 22293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "training...:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "training...:   2%|▎         | 1/40 [00:00<00:03,  9.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:   8%|▊         | 3/40 [00:00<00:03, 10.66it/s]\u001b[A\n",
            "training...:  12%|█▎        | 5/40 [00:00<00:03, 11.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  18%|█▊        | 7/40 [00:00<00:02, 11.46it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  22%|██▎       | 9/40 [00:00<00:02, 11.61it/s]\u001b[A\n",
            "training...:  28%|██▊       | 11/40 [00:00<00:02, 11.69it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  32%|███▎      | 13/40 [00:01<00:02, 11.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  38%|███▊      | 15/40 [00:01<00:02, 11.73it/s]\u001b[A\n",
            "training...:  42%|████▎     | 17/40 [00:01<00:01, 11.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  48%|████▊     | 19/40 [00:01<00:01, 11.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  52%|█████▎    | 21/40 [00:01<00:01, 11.78it/s]\u001b[A\n",
            "training...:  57%|█████▊    | 23/40 [00:01<00:01, 11.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  62%|██████▎   | 25/40 [00:02<00:01, 11.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  68%|██████▊   | 27/40 [00:02<00:01, 11.85it/s]\u001b[A\n",
            "training...:  72%|███████▎  | 29/40 [00:02<00:00, 11.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  78%|███████▊  | 31/40 [00:02<00:00, 11.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  82%|████████▎ | 33/40 [00:02<00:00, 11.81it/s]\u001b[A\n",
            "training...:  88%|████████▊ | 35/40 [00:02<00:00, 11.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  92%|█████████▎| 37/40 [00:03<00:00, 11.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...: 100%|██████████| 40/40 [00:03<00:00, 11.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([32, 256, 300])\n",
            "embedded shape torch.Size([32, 1, 256, 300])\n",
            "conved0 shape torch.Size([32, 100, 249])\n",
            "conved1 shape torch.Size([32, 100, 241])\n",
            "pooled0 shape torch.Size([32, 100])\n",
            "pooled1 shape torch.Size([32, 100])\n",
            "cat shape torch.Size([32, 200])\n",
            "prediction shape torch.Size([32, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:03<00:15,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([392, 256, 300])\n",
            "embedded shape torch.Size([392, 1, 256, 300])\n",
            "conved0 shape torch.Size([392, 100, 249])\n",
            "conved1 shape torch.Size([392, 100, 241])\n",
            "pooled0 shape torch.Size([392, 100])\n",
            "pooled1 shape torch.Size([392, 100])\n",
            "cat shape torch.Size([392, 200])\n",
            "prediction shape torch.Size([392, 2])\n",
            "epoch: 0\n",
            "train_loss: 0.642, train_acc: 0.651\n",
            "valid_loss: 0.472, valid_acc: 0.809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "training...:   5%|▌         | 2/40 [00:00<00:03, 12.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  10%|█         | 4/40 [00:00<00:03, 11.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  15%|█▌        | 6/40 [00:00<00:02, 11.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  20%|██        | 8/40 [00:00<00:02, 11.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  25%|██▌       | 10/40 [00:00<00:02, 11.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  30%|███       | 12/40 [00:01<00:02, 11.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  35%|███▌      | 14/40 [00:01<00:02, 11.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  40%|████      | 16/40 [00:01<00:02, 11.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  45%|████▌     | 18/40 [00:01<00:01, 11.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  50%|█████     | 20/40 [00:01<00:01, 11.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  55%|█████▌    | 22/40 [00:01<00:01, 11.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  60%|██████    | 24/40 [00:02<00:01, 11.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  65%|██████▌   | 26/40 [00:02<00:01, 11.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  70%|███████   | 28/40 [00:02<00:01, 11.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  75%|███████▌  | 30/40 [00:02<00:00, 11.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  80%|████████  | 32/40 [00:02<00:00, 11.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  85%|████████▌ | 34/40 [00:02<00:00, 11.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  90%|█████████ | 36/40 [00:03<00:00, 11.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  95%|█████████▌| 38/40 [00:03<00:00, 11.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining...: 100%|██████████| 40/40 [00:03<00:00, 12.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([32, 256, 300])\n",
            "embedded shape torch.Size([32, 1, 256, 300])\n",
            "conved0 shape torch.Size([32, 100, 249])\n",
            "conved1 shape torch.Size([32, 100, 241])\n",
            "pooled0 shape torch.Size([32, 100])\n",
            "pooled1 shape torch.Size([32, 100])\n",
            "cat shape torch.Size([32, 200])\n",
            "prediction shape torch.Size([32, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:07<00:11,  3.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([392, 256, 300])\n",
            "embedded shape torch.Size([392, 1, 256, 300])\n",
            "conved0 shape torch.Size([392, 100, 249])\n",
            "conved1 shape torch.Size([392, 100, 241])\n",
            "pooled0 shape torch.Size([392, 100])\n",
            "pooled1 shape torch.Size([392, 100])\n",
            "cat shape torch.Size([392, 200])\n",
            "prediction shape torch.Size([392, 2])\n",
            "epoch: 1\n",
            "train_loss: 0.399, train_acc: 0.827\n",
            "valid_loss: 0.352, valid_acc: 0.847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:   5%|▌         | 2/40 [00:00<00:03, 12.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  10%|█         | 4/40 [00:00<00:03, 11.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  15%|█▌        | 6/40 [00:00<00:02, 11.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  20%|██        | 8/40 [00:00<00:02, 11.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  25%|██▌       | 10/40 [00:00<00:02, 11.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  30%|███       | 12/40 [00:01<00:02, 11.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  35%|███▌      | 14/40 [00:01<00:02, 11.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  40%|████      | 16/40 [00:01<00:02, 11.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  45%|████▌     | 18/40 [00:01<00:01, 11.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  50%|█████     | 20/40 [00:01<00:01, 11.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  55%|█████▌    | 22/40 [00:01<00:01, 11.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  60%|██████    | 24/40 [00:02<00:01, 11.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  65%|██████▌   | 26/40 [00:02<00:01, 11.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  70%|███████   | 28/40 [00:02<00:01, 11.47it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  75%|███████▌  | 30/40 [00:02<00:00, 11.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  80%|████████  | 32/40 [00:02<00:00, 11.37it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  85%|████████▌ | 34/40 [00:02<00:00, 11.50it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  90%|█████████ | 36/40 [00:03<00:00, 11.63it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  95%|█████████▌| 38/40 [00:03<00:00, 11.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining...: 100%|██████████| 40/40 [00:03<00:00, 11.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([32, 256, 300])\n",
            "embedded shape torch.Size([32, 1, 256, 300])\n",
            "conved0 shape torch.Size([32, 100, 249])\n",
            "conved1 shape torch.Size([32, 100, 241])\n",
            "pooled0 shape torch.Size([32, 100])\n",
            "pooled1 shape torch.Size([32, 100])\n",
            "cat shape torch.Size([32, 200])\n",
            "prediction shape torch.Size([32, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:11<00:07,  3.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([392, 256, 300])\n",
            "embedded shape torch.Size([392, 1, 256, 300])\n",
            "conved0 shape torch.Size([392, 100, 249])\n",
            "conved1 shape torch.Size([392, 100, 241])\n",
            "pooled0 shape torch.Size([392, 100])\n",
            "pooled1 shape torch.Size([392, 100])\n",
            "cat shape torch.Size([392, 200])\n",
            "prediction shape torch.Size([392, 2])\n",
            "epoch: 2\n",
            "train_loss: 0.298, train_acc: 0.877\n",
            "valid_loss: 0.301, valid_acc: 0.872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:   5%|▌         | 2/40 [00:00<00:03, 12.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  10%|█         | 4/40 [00:00<00:03, 11.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  15%|█▌        | 6/40 [00:00<00:02, 11.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  20%|██        | 8/40 [00:00<00:02, 12.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  25%|██▌       | 10/40 [00:00<00:02, 11.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  30%|███       | 12/40 [00:01<00:02, 11.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  35%|███▌      | 14/40 [00:01<00:02, 11.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  40%|████      | 16/40 [00:01<00:02, 11.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  45%|████▌     | 18/40 [00:01<00:01, 11.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  50%|█████     | 20/40 [00:01<00:01, 11.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  55%|█████▌    | 22/40 [00:01<00:01, 11.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  60%|██████    | 24/40 [00:02<00:01, 11.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  65%|██████▌   | 26/40 [00:02<00:01, 11.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  70%|███████   | 28/40 [00:02<00:01, 11.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  75%|███████▌  | 30/40 [00:02<00:00, 11.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  80%|████████  | 32/40 [00:02<00:00, 11.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  85%|████████▌ | 34/40 [00:02<00:00, 11.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  90%|█████████ | 36/40 [00:03<00:00, 11.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  95%|█████████▌| 38/40 [00:03<00:00, 11.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining...: 100%|██████████| 40/40 [00:03<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([32, 256, 300])\n",
            "embedded shape torch.Size([32, 1, 256, 300])\n",
            "conved0 shape torch.Size([32, 100, 249])\n",
            "conved1 shape torch.Size([32, 100, 241])\n",
            "pooled0 shape torch.Size([32, 100])\n",
            "pooled1 shape torch.Size([32, 100])\n",
            "cat shape torch.Size([32, 200])\n",
            "prediction shape torch.Size([32, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:15<00:03,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([392, 256, 300])\n",
            "embedded shape torch.Size([392, 1, 256, 300])\n",
            "conved0 shape torch.Size([392, 100, 249])\n",
            "conved1 shape torch.Size([392, 100, 241])\n",
            "pooled0 shape torch.Size([392, 100])\n",
            "pooled1 shape torch.Size([392, 100])\n",
            "cat shape torch.Size([392, 200])\n",
            "prediction shape torch.Size([392, 2])\n",
            "epoch: 3\n",
            "train_loss: 0.231, train_acc: 0.910\n",
            "valid_loss: 0.286, valid_acc: 0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:   5%|▌         | 2/40 [00:00<00:03, 11.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  10%|█         | 4/40 [00:00<00:03, 11.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  15%|█▌        | 6/40 [00:00<00:02, 11.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  20%|██        | 8/40 [00:00<00:02, 11.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  25%|██▌       | 10/40 [00:00<00:02, 11.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  30%|███       | 12/40 [00:01<00:02, 11.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  35%|███▌      | 14/40 [00:01<00:02, 11.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  40%|████      | 16/40 [00:01<00:02, 11.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  45%|████▌     | 18/40 [00:01<00:01, 11.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  50%|█████     | 20/40 [00:01<00:01, 11.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  55%|█████▌    | 22/40 [00:01<00:01, 11.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  60%|██████    | 24/40 [00:02<00:01, 11.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  65%|██████▌   | 26/40 [00:02<00:01, 11.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  70%|███████   | 28/40 [00:02<00:01, 11.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  75%|███████▌  | 30/40 [00:02<00:00, 11.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  80%|████████  | 32/40 [00:02<00:00, 11.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  85%|████████▌ | 34/40 [00:02<00:00, 11.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  90%|█████████ | 36/40 [00:03<00:00, 11.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training...:  95%|█████████▌| 38/40 [00:03<00:00, 11.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining...: 100%|██████████| 40/40 [00:03<00:00, 12.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([32, 256, 300])\n",
            "embedded shape torch.Size([32, 1, 256, 300])\n",
            "conved0 shape torch.Size([32, 100, 249])\n",
            "conved1 shape torch.Size([32, 100, 241])\n",
            "pooled0 shape torch.Size([32, 100])\n",
            "pooled1 shape torch.Size([32, 100])\n",
            "cat shape torch.Size([32, 200])\n",
            "prediction shape torch.Size([32, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([512, 256, 300])\n",
            "embedded shape torch.Size([512, 1, 256, 300])\n",
            "conved0 shape torch.Size([512, 100, 249])\n",
            "conved1 shape torch.Size([512, 100, 241])\n",
            "pooled0 shape torch.Size([512, 100])\n",
            "pooled1 shape torch.Size([512, 100])\n",
            "cat shape torch.Size([512, 200])\n",
            "prediction shape torch.Size([512, 2])\n",
            "first embedded shape torch.Size([392, 256, 300])\n",
            "embedded shape torch.Size([392, 1, 256, 300])\n",
            "conved0 shape torch.Size([392, 100, 249])\n",
            "conved1 shape torch.Size([392, 100, 241])\n",
            "pooled0 shape torch.Size([392, 100])\n",
            "pooled1 shape torch.Size([392, 100])\n",
            "cat shape torch.Size([392, 200])\n",
            "prediction shape torch.Size([392, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:19<00:00,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 4\n",
            "train_loss: 0.175, train_acc: 0.938\n",
            "valid_loss: 0.282, valid_acc: 0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 128\n",
        "# train_loader = data_loader(train_dataset, batch_size, pad_sequence,shuffle=True)\n",
        "# valid_loader = data_loader(valid_dataset, batch_size, pad_sequence)\n",
        "# test_loader = data_loader(test_dataset, batch_size,  pad_sequence)\n",
        "\n",
        "# print(f\"length of vocab: {len(vocab)}\")\n",
        "\n",
        "\n",
        "# # build CNN using a predefined kernel size, not necessily use all the embed dimension, very computationally expensive!!!!\n",
        "# # also because need to eventually reduce dimension, it is not learning any better neither\n",
        "# class myCNN(torch.nn.Module):\n",
        "#   def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
        "#     super().__init__()\n",
        "#     self.embedding = torch.nn.Embedding(vocab_size, embedding_dim,padding_idx=pad_idx)\n",
        "#     self.conv0 = torch.nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=filter_sizes[0])\n",
        "#     self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=filter_sizes[1])\n",
        "#     self.fc = torch.nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "#     self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "#   def forward(self, ids):\n",
        "#     # [batch_size, seq_len] at beginning\n",
        "#     embedded = self.dropout(self.embedding(ids))\n",
        "#     print(f\"first embedded shape {embedded.shape}\")\n",
        "#     # [batch_size,seq_len, embed_dimsion]\n",
        "#     embedded = embedded.unsqueeze(1) # In PyTorch, unsqueeze(dim) adds a new dimension of size one at the specified dim. For unsqueeze(1), 256*300 becomes 1*256*300\n",
        "#     print(f\"embedded shape {embedded.shape}\")\n",
        "#     # [batch_size, 1, seq_len, dimension]\n",
        "#     conved0 = torch.relu(self.conv0(embedded).squeeze(3)) # in\n",
        "#     print(f\"conved0 shape {conved0.shape}\")\n",
        "#     # [batch_size, n_filters, seq_len - filter_size+1]\n",
        "#     conved1 = torch.relu(self.conv1(embedded).squeeze(3))\n",
        "#     print(f\"conved1 shape {conved1.shape}\")\n",
        "#     output, _ = torch.max(conved0, dim=-1, keepdim=True) # max pooling by get the max of last dim\n",
        "#     pooled0 = output.squeeze(3)\n",
        "#     print(f\"middle pooled0 shape {pooled0.shape}\")\n",
        "#     output, _ = torch.max(pooled0, dim=-1, keepdim=True) # max pooling by get the max of last dim\n",
        "#     pooled0 = output.squeeze(2)\n",
        "#     print(f\"pooled0 shape {pooled0.shape}\")\n",
        "#     # [batch_size,n_filters]\n",
        "#     output, _ = torch.max(conved1, dim=-1, keepdim=True)\n",
        "#     pooled1 = output.squeeze(3)\n",
        "#     print(f\"middle pooled1 shape {pooled0.shape}\")\n",
        "#     output, _ = torch.max(pooled1, dim=-1, keepdim=True) # max pooling by get the max of last dim\n",
        "#     pooled1 = output.squeeze(2)\n",
        "#     print(f\"pooled1 shape {pooled1.shape}\")\n",
        "#     cat = self.dropout(torch.cat((pooled0, pooled1), dim=1))\n",
        "#     print(f\"cat shape {cat.shape}\")\n",
        "#     prediction = self.fc(cat)\n",
        "#     print(f\"prediction shape {prediction.shape}\")\n",
        "#     return prediction\n",
        "\n",
        "# vocab_size = len(vocab)\n",
        "# embed_dim = 300\n",
        "# n_filters = 100\n",
        "# filter_sizes = [(8,200),(16,200)] # this actually means a filter with 8*embed_dimension, 16*embed_dimension\n",
        "# # this is saying that we are looking at 8-gram, 16-gram, so these values usually  are 2,3,4\n",
        "# # note we can also use something like [(8,8),(16,16)]\n",
        "# output_dim = len(train_dataset.unique(\"label\"))\n",
        "# dropout = 0.25\n",
        "# pad_idx = vocab[\"<pad>\"]\n",
        "\n",
        "# model = myCNN(vocab_size, embed_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx)\n",
        "\n",
        "# vectors = torchtext.vocab.GloVe(name='6B',dim=300)\n",
        "# pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n",
        "# model.embedding.weight.data = pretrained_embedding\n",
        "\n",
        "\n",
        "# def count_parameters(model):\n",
        "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "# print(f\"The model has {count_parameters(model):,} trainable parameters\")\n",
        "\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "\n",
        "\n",
        "# def accuracy(prediction, label):\n",
        "#     batch_size, _ = prediction.shape\n",
        "#     predicted_classes = prediction.argmax(dim=-1)\n",
        "#     correct_predictions = predicted_classes.eq(label).sum()\n",
        "#     accuracy = correct_predictions / batch_size\n",
        "#     return accuracy\n",
        "# #\n",
        "\n",
        "# optim = optim.Adam(model.parameters(), lr=0.001)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# criterion.to(device)\n",
        "# model.to(device)\n",
        "\n",
        "# # define train function with batch\n",
        "# def train(model, data_loader, optimizer, criterion):\n",
        "#   epoch_loss = 0\n",
        "#   epoch_acc = 0\n",
        "#   model.train()\n",
        "#   for batch in tqdm.tqdm(data_loader, desc=\"training...\"):\n",
        "#     ids = batch['ids'].to(device)\n",
        "#     labels = batch['labels'].to(device)\n",
        "#     optimizer.zero_grad()\n",
        "#     predictions = model(ids).squeeze(1)\n",
        "#     loss = criterion(predictions, labels)\n",
        "#     acc = accuracy(predictions, labels)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     epoch_loss += loss.item()\n",
        "#     epoch_acc += acc.item()\n",
        "#   return epoch_loss / len(data_loader), epoch_acc / len(data_loader)\n",
        "\n",
        "# def evaluate(model, data_loader, criterion):\n",
        "#   epoch_loss = 0\n",
        "#   epoch_acc = 0\n",
        "#   model.eval()\n",
        "#   with torch.no_grad():\n",
        "#     for batch in data_loader:\n",
        "#       ids = batch['ids'].to(device)\n",
        "#       labels = batch['labels'].to(device)\n",
        "#       predictions = model(ids).squeeze(1)\n",
        "#       loss = criterion(predictions, labels)\n",
        "#       acc = accuracy(predictions, labels)\n",
        "#       epoch_loss += loss.item()\n",
        "#       epoch_acc += acc.item()\n",
        "\n",
        "#   return epoch_loss / len(data_loader), epoch_acc / len(data_loader)\n",
        "\n",
        "\n",
        "# epochs= 1\n",
        "# # loop through epoch and record train and valid loss and accurcay\n",
        "# from collections import defaultdict\n",
        "# import tqdm\n",
        "\n",
        "# train_loss = defaultdict(list)\n",
        "# train_acc = defaultdict(list)\n",
        "# valid_loss = defaultdict(list)\n",
        "# valid_acc = defaultdict(list)\n",
        "# for epoch in tqdm.tqdm(range(epochs)):\n",
        "#   train_loss_epoch, train_acc_epoch = train(model, train_loader, optim, criterion)\n",
        "#   valid_loss_epoch, valid_acc_epoch = evaluate(model, valid_loader, criterion)\n",
        "#   train_loss[epoch].append(train_loss_epoch)\n",
        "#   train_acc[epoch].append(train_acc_epoch)\n",
        "#   valid_loss[epoch].append(valid_loss_epoch)\n",
        "#   valid_acc[epoch].append(valid_acc_epoch)\n",
        "#   print(f\"epoch: {epoch}\")\n",
        "#   print(f\"train_loss: {train_loss_epoch:.3f}, train_acc: {train_acc_epoch:.3f}\")\n",
        "#   print(f\"valid_loss: {valid_loss_epoch:.3f}, valid_acc: {valid_acc_epoch:.3f}\")\n",
        "\n",
        "# # plot train and valid loss\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(train_loss.values(), label='train loss')\n",
        "# plt.plot(valid_loss.values(), label='valid loss')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # plot train and valid accuracy\n",
        "# plt.plot(train_acc.values(), label='train acc')\n",
        "# plt.plot(valid_acc.values(), label='valid acc')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S5caSIzqNOK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FygitOmfdbKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}